## Dialogue and Machine Reading

### Overview

#### 이러한 현상의 이유

* 메신저 앱 사용의 증가
  * 라인, 카카오톡, 페이스북메신저 등..

* AI 스피커가 새롭게 등장
  * 물어보고 알아듣는 것과 같이, 사람들의 정보 접근 방식이 달라졌음
    * (이전에는 검색하고 읽었음)

#### Dialogue Service

* 뭔데? AI 스피커
* 어떻게 만들지?
  * 어떻게 대답해줄건데?
    1. Rule base
       1. 미리 문장을 만들어놓음
       2. 대부분
    2. Generating response
       1. 1번과 달리, 실제 문장을 만든다
       2. GAN
  * Domain (영역)
    1. Open
       1. ex) 인터넷 검색을 해서 답을 찾아줄 수 있다
       2. 굉장히 넓은 범위
    2. Close
       1. ex) 가천대 학생들의 질문 300개에 대해서 만들어봤어



### Rule-based model (실제는 여기로 구현)

* Database retrieval
  * How to
    * (BOW 등을 사용하여) feature를 뽑아서, 의도를 classification 한다
    * BOW
      * 각 단어가 몇번 등장하였는가?
      * 짧은 문장은 BOW가 더 작동한다
      * TF-IDF
        * 많이 나올수록 가중치를 적게 주어서, 특정 문서에서만 나오는 단어를 알아내다
    * Word embedding
      * vector space
* Knowledge Base

### Generative Model (연구로는 여기에 집중)

* Text generation



## Models of Chat

#### Basic Generation model

- MT처럼, LSTM에 인코더, 디코더를 사용하는게 가장 기본적인 방식
- Problem 1: Dialog More Dependent on Global Coherence
  - 질의와 응답은, 상황을 고려한다
  - 따라서 기존의 MT에서의 방법은 좋은 효과를 내지 못했다
  - Sol 1: 대화를 길게 넣어보자
    - LSTM을 길게 넣는다



## Multi-Turn generation

이전의 대화를 인식할 수 있는 것

이전에 있는 대화를 vector화 해놓는다. 그리고 현재 대화의 vector값과 연산을 하여, memory (기억)을 만들어준다

* 문제점
  * 메모리가 많아질 수록 학습할 양이 지나치게 많아진다



## Site

데이터셋 : Google dataset



장난이 아니야. 설렁설렁 시간때우듯이 해서는 안돼.

매일 공부하고, 머릿속에 지식을 넣어야 해.

모르는 것이 있으면, 쉽게 넘어가서는 안돼. 

물론 매번 짚고넘어갈 수는 없지만, 적어도 짚지 못하였다면 표시해두고 나중에 알아봐야해.